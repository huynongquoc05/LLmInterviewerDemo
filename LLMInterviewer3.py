# AdaptiveInterviewer: AI Interviewer vá»›i State Machine thÃ´ng minh
import datetime

from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings
from GetApikey import loadapi

from dataclasses import dataclass
from typing import List, Dict, Optional
from enum import Enum


# =======================
# 1. Enums & Data Classes
# =======================

class Level(Enum):
    YEU = "yeu"  # <5
    TRUNG_BINH = "trung_binh"  # 5-6.5
    KHA = "kha"  # 6.5-8
    GIOI = "gioi"  # 8-9
    XUAT_SAC = "xuat_sac"  # 9-10


class QuestionDifficulty(Enum):
    VERY_EASY = "very_easy"
    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"
    VERY_HARD = "very_hard"


@dataclass
class QuestionAttempt:
    question: str
    answer: str
    score: float
    analysis: str
    difficulty: QuestionDifficulty
    timestamp: str


@dataclass
class InterviewState:
    candidate_name: str
    profile: str
    level: Level
    topic: str
    current_difficulty: QuestionDifficulty
    attempts_at_current_level: int
    max_attempts_per_level: int
    total_questions_asked: int
    max_total_questions: int
    upper_level_reached: int
    history: List[QuestionAttempt]
    is_finished: bool
    final_score: Optional[float] = None


# =======================
# 2. Configuration & Thresholds
# =======================

class InterviewConfig:
    # Thresholds Ä‘á»ƒ quyáº¿t Ä‘á»‹nh next step
    THRESHOLD_HIGH = 7.0  # >= 7: chuyá»ƒn lÃªn khÃ³ hÆ¡n
    THRESHOLD_LOW = 4.0  # < 4: giáº£m xuá»‘ng dá»… hÆ¡n

    # Limits
    MAX_ATTEMPTS_PER_LEVEL = 2
    MAX_TOTAL_QUESTIONS = 8
    MAX_UPPER_LEVEL = 2  # max level cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c

    # Difficulty progression mapping
    DIFFICULTY_MAP = {
        Level.YEU: [QuestionDifficulty.VERY_EASY, QuestionDifficulty.EASY],
        Level.TRUNG_BINH: [QuestionDifficulty.EASY, QuestionDifficulty.EASY],
        Level.KHA: [QuestionDifficulty.MEDIUM, QuestionDifficulty.HARD],
        Level.GIOI: [QuestionDifficulty.MEDIUM, QuestionDifficulty.VERY_HARD],
        Level.XUAT_SAC: [QuestionDifficulty.HARD, QuestionDifficulty.VERY_HARD],
    }


# =======================
# 3. Utility Functions
# =======================

def classify_level_from_score(score_40: float) -> Level:
    """PhÃ¢n loáº¡i level dá»±a trÃªn Ä‘iá»ƒm 40%"""
    if score_40 < 5.0:
        return Level.YEU
    elif score_40 <= 6.5:
        return Level.TRUNG_BINH
    elif score_40 <= 8.0:
        return Level.KHA
    elif score_40 <= 9.0:
        return Level.GIOI
    else:
        return Level.XUAT_SAC


def get_initial_difficulty(level: Level) -> QuestionDifficulty:
    """Láº¥y Ä‘á»™ khÃ³ ban Ä‘áº§u cho level"""
    return InterviewConfig.DIFFICULTY_MAP[level][0]


def get_next_difficulty(current: QuestionDifficulty, action: str) -> QuestionDifficulty:
    """TÃ­nh Ä‘á»™ khÃ³ tiáº¿p theo dá»±a trÃªn action (harder/same/easier)"""
    difficulties = list(QuestionDifficulty)
    current_idx = difficulties.index(current)

    if action == "harder" and current_idx < len(difficulties) - 1:
        return difficulties[current_idx + 1]
    elif action == "easier" and current_idx > 0:
        return difficulties[current_idx - 1]
    else:  # same or can't change
        return current


import json, re

import re
import json

def _clean_and_parse_json_response(raw_text: str, expected_keys: list[str] = None) -> dict:
    """
    Parse JSON tá»« LLM, xá»­ lÃ½ cáº£ khi trong string cÃ³ code block hoáº·c text thá»«a.
    Náº¿u cÃ³ code block, sáº½ ná»‘i code vÃ o trÆ°á»ng 'question' thay vÃ¬ tÃ¡ch riÃªng.
    """
    if not raw_text:
        return {}

    text = raw_text.strip()

    # 1) TÃ¬m code block (java, python...)
    code_match = re.search(r"```(?:[a-zA-Z0-9]+)?\s*(.*?)\s*```", text, flags=re.S)
    code_snippet = code_match.group(1).strip() if code_match else None

    # 2) Thá»­ parse JSON object trong toÃ n bá»™ text
    first_brace = text.find('{')
    last_brace = text.rfind('}')
    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
        candidate = text[first_brace:last_brace + 1]
        # Loáº¡i bá» code fences
        candidate = re.sub(r"```[a-zA-Z]*", "", candidate)
        candidate = candidate.replace("```", "")

        # Escape xuá»‘ng dÃ²ng trong string
        def _escape_newlines_in_strings(match):
            inner = match.group(0)
            return inner.replace("\n", "\\n")
        candidate = re.sub(r'\".*?\"', _escape_newlines_in_strings, candidate, flags=re.S)

        try:
            parsed = json.loads(candidate)
            if expected_keys:
                parsed = {k: v for k, v in parsed.items() if k in expected_keys}
            # Ná»‘i code vÃ o question náº¿u cÃ³
            if code_snippet and "question" in parsed:
                parsed["question"] += "\n\n" + code_snippet
            return parsed
        except Exception as e:
            print(f"âš ï¸ JSON parse error after cleaning: {e}")

    # 3) Náº¿u tháº¥t báº¡i, fallback sang parse single question
    return {"question": _clean_and_parse_single_question(text, code_snippet)}


def _clean_and_parse_single_question(raw_text: str, code_snippet: str = None) -> str:
    """
    Input: raw_text tá»« LLM (cÃ³ thá»ƒ kÃ¨m ```json``` hoáº·c lá»™n xá»™n)
    Output: 1 string cÃ¢u há»i sáº¡ch, kÃ¨m code snippet náº¿u cÃ³
    """
    if not raw_text:
        return ""

    text = raw_text.strip()

    # 1) Náº¿u cÃ³ code fence JSON
    code_fence_match = re.search(r"```(?:json)?\s*(.*?)\s*```", text, flags=re.S | re.I)
    if code_fence_match:
        text = code_fence_match.group(1).strip()

    # 2) Thá»­ parse JSON object
    first_brace = text.find('{')
    last_brace = text.rfind('}')
    if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
        candidate = text[first_brace:last_brace + 1]
        try:
            parsed = json.loads(candidate)
            if isinstance(parsed, dict) and "question" in parsed:
                q = _sanitize_question(parsed["question"])
                if code_snippet:
                    q += "\n\n" + code_snippet
                return q
        except Exception:
            pass

    # 3) Náº¿u tháº¥t báº¡i, thá»­ tÃ¬m chuá»—i trong ngoáº·c kÃ©p
    quoted = re.findall(r'"([^"]{10,})"', text, flags=re.S)
    if quoted:
        q = _sanitize_question(quoted[0])
        if code_snippet:
            q += "\n\n" + code_snippet
        return q

    # 4) Fallback: láº¥y dÃ²ng dÃ i nháº¥t lÃ m cÃ¢u há»i
    lines = [ln.strip() for ln in text.splitlines() if len(ln.strip()) > 20]
    if lines:
        q = _sanitize_question(max(lines, key=len))
        if code_snippet:
            q += "\n\n" + code_snippet
        return q

    return code_snippet or ""


def _sanitize_question(q: str) -> str:
    """LÃ m sáº¡ch cÃ¢u há»i: bá» backticks, quotes, sá»‘ thá»© tá»±..."""
    s = str(q).strip()
    s = re.sub(r'^[`\"]+|[`\"]+$', '', s).strip()
    s = re.sub(r'^\s*"\s*', '', s)
    s = re.sub(r'^\s*\(?\d+\)?[\).\s:-]+\s*', '', s)
    s = s.rstrip(",;}]")
    return s.strip()


# =======================
# 4. Core Interviewer Class
# =======================

class AdaptiveInterviewer:
    def __init__(self):
        # Load components
        self.api_key = loadapi()
        self.embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large-instruct")
        self.cv_db = FAISS.load_local("vector_db_csv", self.embeddings, allow_dangerous_deserialization=True)
        self.knowledge_db = FAISS.load_local("vector_db2chunk_nltk", self.embeddings,
                                             allow_dangerous_deserialization=True)
        self.retriever = self.knowledge_db.as_retriever(search_kwargs={"k": 5})
        self.llm = GoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=self.api_key,
            temperature=0.5
        )
        # === New: conversation memory (simple list) ===
        self.memory: list[dict] = []
        self.max_memory_turns = 6   # chá»‰ giá»¯ 6 lÆ°á»£t gáº§n nháº¥t
        self.sessions: dict[str, InterviewState] = {}  # giá»¯ state theo candidate_name
        self.knowledge_text=None

    # ============ Memory Helpers ============
    def add_to_memory(self, role: str, content: str):
        """ThÃªm má»™t Ä‘oáº¡n há»™i thoáº¡i vÃ o memory."""
        self.memory.append({"role": role, "content": content})
        self.memory = self.memory[-self.max_memory_turns:]  # cáº¯t bá»›t náº¿u quÃ¡ dÃ i

    def build_history_prompt(self) -> str:
        """GhÃ©p memory thÃ nh Ä‘oáº¡n há»™i thoáº¡i Ä‘á»ƒ truyá»n vÃ o LLM."""
        if not self.memory:
            return ""
        return "\n".join([f"{m['role']}: {m['content']}" for m in self.memory])

    def load_candidate_profile(self, candidate_name: str) -> tuple[str, Level]:
        """Load há»“ sÆ¡ vÃ  phÃ¢n loáº¡i level"""
        profile_docs = self.cv_db.similarity_search(candidate_name, k=1)
        if not profile_docs:
            raise ValueError(f"KhÃ´ng tÃ¬m tháº¥y há»“ sÆ¡ cho {candidate_name}")

        profile_content = profile_docs[0].page_content

        # Extract Ä‘iá»ƒm 40% tá»« profile (giáº£ sá»­ cÃ³ format chuáº©n)
        score_match = re.search(r'Äiá»ƒm 40%[:\s]+([0-9.]+)', profile_content)
        if score_match:
            score_40 = float(score_match.group(1))
            level = classify_level_from_score(score_40)
        else:
            # Fallback: dÃ¹ng LLM Ä‘á»ƒ classify
            level = self._classify_level_with_llm(profile_content)

        return profile_content, level

    def build_knowledge_context(self, topic: str, outline: list[str] | None = None) -> str:
        """
        Táº¡o ngá»¯ cáº£nh kiáº¿n thá»©c dá»±a trÃªn topic vÃ  optional outline.
        - Náº¿u cÃ³ outline: search nhiá»u query (topic + tá»«ng má»¥c outline).
        - Náº¿u khÃ´ng cÃ³: search theo topic.
        Tráº£ vá»: text ghÃ©p ná»‘i tá»« cÃ¡c tÃ i liá»‡u.
        """
        results = []

        if outline and len(outline) > 0:
            # Multiple query
            for item in outline:
                query = f"{topic} {item}"
                docs = self.retriever.invoke(query)
                results.extend(docs)
        else:
            # Single query
            docs = self.retriever.invoke(topic)
            results.extend(docs)

        # Loáº¡i trÃ¹ng láº·p (theo page_content)
        seen = set()
        unique_docs = []
        for doc in results:
            if doc.page_content not in seen:
                seen.add(doc.page_content)
                unique_docs.append(doc)

        knowledge_text = "\n\n".join([doc.page_content for doc in unique_docs])
        self.knowledge_text=knowledge_text

    def _classify_level_with_llm(self, profile: str) -> Level:
        """Fallback method Ä‘á»ƒ classify level báº±ng LLM"""
        classify_prompt = f"""
        Báº¡n lÃ  má»™t Interviewer AI vÃ  Ä‘ang chuáº©n bá»‹ phá»ng váº¥n bÃ i thi váº¥n Ä‘Ã¡p cá»§a 1 thÃ­ sinh .
        PhÃ¢n loáº¡i trÃ¬nh Ä‘á»™ thÃ­ sinh theo Ä‘iá»ƒm 40%: Yáº¿u (<5), Trung bÃ¬nh (5-6.5), KhÃ¡ (6.5-8), Giá»i (8-9), Xuáº¥t sáº¯c (9-10).

        Há»“ sÆ¡: {profile}

        Tráº£ vá» JSON: {{"level": "yeu|trung_binh|kha|gioi|xuat_sac"}}
        """
        result = self.llm.invoke(classify_prompt)
        parsed = _clean_and_parse_json_response(result, ["level"])
        level_str = parsed.get("level", "trung_binh")

        # Convert to enum
        level_mapping = {
            "yeu": Level.YEU,
            "trung_binh": Level.TRUNG_BINH,
            "kha": Level.KHA,
            "gioi": Level.GIOI,
            "xuat_sac": Level.XUAT_SAC
        }
        return level_mapping.get(level_str, Level.TRUNG_BINH)

    def generate_question(self, topic: str, difficulty: QuestionDifficulty, context: str = "") -> str:
        """Generate cÃ¢u há»i theo topic vÃ  Ä‘á»™ khÃ³"""
        # knowledge_context = self.retriever.invoke(f"{topic} {difficulty.value}")
        # knowledge_text = "\n\n".join([doc.page_content for doc in knowledge_context])
        history_text = self.build_history_prompt()  # Láº¥y lá»‹ch sá»­ há»™i thoáº¡i
        #print("history_text:", history_text)
        difficulty_descriptions = {
            QuestionDifficulty.VERY_EASY: "ráº¥t cÆ¡ báº£n, Ä‘á»‹nh nghÄ©a Ä‘Æ¡n giáº£n",
            QuestionDifficulty.EASY: "cÆ¡ báº£n, vÃ­ dá»¥ thá»±c táº¿",
            QuestionDifficulty.MEDIUM: "trung cáº¥p, á»©ng dá»¥ng thá»±c táº¿",
            QuestionDifficulty.HARD: "nÃ¢ng cao, phÃ¢n tÃ­ch sÃ¢u",
            QuestionDifficulty.VERY_HARD: "ráº¥t khÃ³, tá»•ng há»£p kiáº¿n thá»©c"
        }

        generate_prompt = f"""
        Báº¡n lÃ  má»™t Interviewer AI.
        ÄÃ¢y lÃ  lá»‹ch sá»­ há»™i thoáº¡i gáº§n Ä‘Ã¢y giá»¯a báº¡n vÃ  thÃ­ sinh:
        {history_text}

        Táº¡o 1 cÃ¢u há»i phá»ng váº¥n Java vá» chá»§ Ä‘á» "{topic}" vá»›i Ä‘á»™ khÃ³ "{difficulty_descriptions[difficulty]}".

        QUAN TRá»ŒNG:
        - Chá»‰ sá»­ dá»¥ng kiáº¿n thá»©c trong pháº§n TÃ€I LIá»†U THAM KHáº¢O dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ táº¡o cÃ¢u há»i.
        -cÃ¡c vÃ­ dá»¥ code thÃ¬ báº¡n cÃ³ thá»ƒ sÃ¡ng táº¡o nhÆ°ng pháº£i dá»±a vÃ o kiáº¿n thá»©c trong tÃ i liá»‡u tham kháº£o
        - Náº¿u tÃ i liá»‡u tham kháº£o trá»‘ng hoáº·c khÃ´ng chá»©a thÃ´ng tin liÃªn quan Ä‘áº¿n "{topic}", 
          thÃ¬ KHÃ”NG Ä‘Æ°á»£c tá»± sÃ¡ng táº¡o cÃ¢u há»i, hÃ£y tráº£ vá» JSON:
          {{"question": "KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ táº¡o cÃ¢u há»i."}}

        TÃ€I LIá»†U THAM KHáº¢O:
        {self.knowledge_text if self.knowledge_text else "KhÃ´ng cÃ³ tÃ i liá»‡u"}

        YÃŠU Cáº¦U:
        - CÃ¢u há»i pháº£i rÃµ rÃ ng, cá»¥ thá»ƒ, phÃ¹ há»£p vá»›i Ä‘á»™ khÃ³.
        - TUYá»†T Äá»I KHÃ”NG Ä‘Æ°á»£c dÃ¹ng kiáº¿n thá»©c ngoÃ i tÃ i liá»‡u tham kháº£o.
        - VÃ­ dá»¥ code Ä‘Æ°á»£c phÃ©p dÃ¹ng nhÆ°ng pháº£i dá»±a vÃ o ná»™i dung trong tÃ i liá»‡u.
        - CÃ³ cÃ¢n nháº¯c lá»‹ch sá»­ há»™i thoáº¡i giá»¯a báº¡n vÃ  thÃ­ sinh Ä‘á»ƒ cÃ¢u há»i máº¡ch láº¡c hÆ¡n.
        - VÄƒn phong tá»± nhiÃªn, háº¡n cháº¿ láº·p láº¡i cá»¥m tá»« nhÆ° "theo tÃ i liá»‡u tham kháº£o",â€œtÃ i liá»‡u Ä‘á» cáº­pâ€..., mÃ  thay tháº¿ báº±ng â€œnhá»¯ng gÃ¬ tÃ´i Ä‘Æ°á»£c  biáº¿tâ€â€¦.
        -Äá»ƒ vÄƒn phong tá»± nhiÃªn hÆ¡n , trÆ°á»›c khi Ä‘Æ°a ra ná»™i dung cÃ¢u há»i má»›i, báº¡n hÃ£y dÃ nh 1 lá»i khen, náº¿u thÃ­ sinh tráº£ lá»i tá»‘t cÃ¢u trÆ°á»›c Ä‘Ã³ rá»“i hÃ£y Ä‘Æ°a ra ná»™i dung cÃ¢u há»i, cÃ²n khÃ´ng thÃ¬ thÃ´i.

        Äáº§u ra: 
        - Tráº£ vá» DUY NHáº¤T má»™t object JSON cÃ³ dáº¡ng: {{"question": " lá»i khen (náº¿u cÃ³) + cÃ¢u há»i..."}}
        - KHÃ”NG kÃ¨m lá»i chÃ o, giáº£i thÃ­ch hay code fence (```).
        """
        print("táº¡o ra cÃ¢u há»i vá»›i Ä‘á»™ khÃ³:", difficulty.value)
        result = self.llm.invoke(generate_prompt)
        print("Raw LLM output for question generation:", result)
        # print(result)
        parsed = _clean_and_parse_json_response(result, ["question"])
        # print("self.knowledge_text", self.knowledge_text)

        print("Generated question:", parsed)
        # print(parsed)
        self.add_to_memory("interviewer", parsed.get("question", "HÃ£y giáº£i thÃ­ch vá» Java?"))
         # ThÃªm cÃ¢u há»i vÃ o memory
        # print(self.memory)
        return parsed.get("question", "HÃ£y giáº£i thÃ­ch vá» Java?")

    def evaluate_answer(self, question: str, answer: str, topic: str) -> tuple[float, str]:
        """ÄÃ¡nh giÃ¡ cÃ¢u tráº£ lá»i vÃ  tráº£ vá» (score, analysis)"""
        # Láº¥y ngá»¯ cáº£nh kiáº¿n thá»©c
        knowledge_text = self.knowledge_text if self.knowledge_text else "KhÃ´ng cÃ³ tÃ i liá»‡u"
        history_text = self.build_history_prompt()
        eval_prompt = f"""
        ÄÃ¢y lÃ  lá»‹ch sá»­ há»™i thoáº¡i gáº§n Ä‘Ã¢y:
        {history_text}

        Nhiá»‡m vá»¥: Cháº¥m Ä‘iá»ƒm cÃ¢u tráº£ lá»i phá»ng váº¥n Java (0-10 Ä‘iá»ƒm).

        CÃ¢u há»i: {question}
        CÃ¢u tráº£ lá»i: {answer}

        TÃ€I LIá»†U THAM KHáº¢O (nguá»“n duy nháº¥t Ä‘á»ƒ cháº¥m Ä‘iá»ƒm):
        {knowledge_text}

        QUY Táº®C Báº®T BUá»˜C:
        - Chá»‰ Ä‘Æ°á»£c sá»­ dá»¥ng kiáº¿n thá»©c cÃ³ trong TÃ€I LIá»†U THAM KHáº¢O Ä‘á»ƒ Ä‘Ã¡nh giÃ¡.
        - KHÃ”NG Ä‘Æ°á»£c thÃªm, suy diá»…n hay viá»‡n dáº«n kiáº¿n thá»©c ngoÃ i tÃ i liá»‡u (vÃ­ dá»¥: "reference types" náº¿u tÃ i liá»‡u khÃ´ng Ä‘á» cáº­p).
        - Náº¿u cÃ¢u tráº£ lá»i cÃ³ pháº§n vÆ°á»£t ra ngoÃ i tÃ i liá»‡u, thÃ¬ KHÃ”NG Ä‘Æ°á»£c coi Ä‘Ã³ lÃ  sai. Chá»‰ cáº§n cháº¥m dá»±a trÃªn nhá»¯ng gÃ¬ tÃ i liá»‡u cÃ³.
        - Náº¿u tÃ i liá»‡u khÃ´ng Ä‘á»§ thÃ´ng tin Ä‘á»ƒ kháº³ng Ä‘á»‹nh Ä‘Ãºng/sai, hÃ£y cháº¥m á»Ÿ má»©c trung láº­p (5/10) vÃ  ghi nháº­n xÃ©t: "TÃ i liá»‡u khÃ´ng Ä‘á» cáº­p, khÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ Ä‘áº§y Ä‘á»§."

        Äáº¦U RA Báº®T BUá»˜C:
        Tráº£ vá» JSON duy nháº¥t theo dáº¡ng:
        {{
          "score": <sá»‘ tá»« 0-10>,
          "analysis": "<nháº­n xÃ©t ngáº¯n gá»n, chá»‰ dá»±a trÃªn tÃ i liá»‡u>"
        }}
        """


        # print(history_text)
        result = self.llm.invoke(eval_prompt)
        parsed = _clean_and_parse_json_response(result, ["score", "analysis"])

        score = float(parsed.get("score", 5.0))
        analysis = parsed.get("analysis", "KhÃ´ng cÃ³ nháº­n xÃ©t")
        # === Cáº­p nháº­t memory ===
        self.add_to_memory("student", answer)
        self.add_to_memory("interviewer", f"ğŸ“Š Äiá»ƒm: {score}/10 - {analysis}")
        # print("current memory:", self.memory)
        return score, analysis

    def decide_next_action(self, score: float, state: InterviewState) -> str:
        """Policy Engine: quyáº¿t Ä‘á»‹nh action tiáº¿p theo"""
        if score >= InterviewConfig.THRESHOLD_HIGH:
            return "harder"
        elif score >= InterviewConfig.THRESHOLD_LOW:
            return "same"
        else:
            return "easier"

    def update_state_after_question(self, state: InterviewState,
                                    question: str, answer: str,
                                    score: float, analysis: str) -> None:
        """Update state sau má»—i cÃ¢u há»i (khÃ´ng táº¡o thÃªm attempt má»›i Ä‘á»ƒ trÃ¡nh nhÃ¢n Ä‘Ã´i)"""
        # Cáº­p nháº­t bá»™ Ä‘áº¿m
        state.total_questions_asked += 1

        # Quyáº¿t Ä‘á»‹nh action
        action = self.decide_next_action(score, state)

        if action == "harder":

            state.upper_level_reached += 1
            print('sá»‘ level cháº©n bá»‹ lÃªn:', state.upper_level_reached)
            if state.upper_level_reached <= InterviewConfig.MAX_UPPER_LEVEL:
                state.current_difficulty = get_next_difficulty(state.current_difficulty, "harder")
                state.attempts_at_current_level = 0
            else:
                # ÄÃ£ vÆ°á»£t giá»›i háº¡n nÃ¢ng cáº¥p
                state.is_finished = True

        elif action == "same":
            # Giá»¯ nguyÃªn Ä‘á»™ khÃ³, tÄƒng sá»‘ láº§n á»Ÿ level nÃ y
            state.attempts_at_current_level += 1

        else:  # easier
            # Háº¡ Ä‘á»™ khÃ³, tÄƒng sá»‘ láº§n
            state.current_difficulty = get_next_difficulty(state.current_difficulty, "easier")
            state.attempts_at_current_level += 1
            state.upper_level_reached = max(0, state.upper_level_reached - 1)

        # Kiá»ƒm tra Ä‘iá»u kiá»‡n káº¿t thÃºc
        if (state.attempts_at_current_level >= InterviewConfig.MAX_ATTEMPTS_PER_LEVEL or
                state.total_questions_asked >= InterviewConfig.MAX_TOTAL_QUESTIONS or
                state.is_finished):
            state.is_finished = True
            scores = [attempt.score for attempt in state.history if attempt.score > 0]
            state.final_score = sum(scores) / len(scores) if scores else 0.0

    def start_interview(self, candidate_name: str, topic: str,outline: list[str] | None = None) -> Dict:
        # 1. Load profile + phÃ¢n loáº¡i level
        profile, level = self.load_candidate_profile(candidate_name)
        initial_difficulty = get_initial_difficulty(level)
        self.build_knowledge_context(topic, outline)
        print ('knowledge_text:', self.knowledge_text)
        # 2. Khá»Ÿi táº¡o state
        state = InterviewState(
            candidate_name=candidate_name,
            profile=profile,
            level=level,
            topic=topic,
            current_difficulty=initial_difficulty,
            attempts_at_current_level=0,
            max_attempts_per_level=InterviewConfig.MAX_ATTEMPTS_PER_LEVEL,
            total_questions_asked=0,
            max_total_questions=InterviewConfig.MAX_TOTAL_QUESTIONS,
            history=[],
            is_finished=False
            , upper_level_reached=0,

        )

        # 3. Sinh cÃ¢u há»i Ä‘áº§u tiÃªn
        question = self.generate_question(topic, state.current_difficulty, "Báº¯t Ä‘áº§u phá»ng váº¥n")

        # 4. LÆ°u vÃ o history (chÆ°a cÃ³ answer, score, analysis)
        state.history.append(QuestionAttempt(
            question=question,
            answer="",
            score=0.0,
            analysis="(pending answer)",
            difficulty=state.current_difficulty,
            timestamp=datetime.datetime.now().isoformat()
        ))

        # 5. LÆ°u state vÃ o sessions
        self.sessions[candidate_name] = state

        return {
            "candidate": candidate_name,
            "topic": topic,
            "profile": profile,
            "level": level.value,
            "question": question,
            "difficulty": state.current_difficulty.value,
        }

    def submit_answer(self, candidate_name: str, answer: str) -> Dict:
        # 1. Láº¥y state tá»« sessions
        state = self.sessions.get(candidate_name)
        if not state:
            return {"error": "Interview not started"}

        # 2. Láº¥y cÃ¢u há»i cuá»‘i cÃ¹ng trong history
        if not state.history:
            return {"error": "No question found in history"}
        last_attempt = state.history[-1]
        last_question = last_attempt.question

        # 3. Cháº¥m Ä‘iá»ƒm
        score, analysis = self.evaluate_answer(last_question, answer, state.topic)
        print('answer:', answer)
        print(f"Evaluated answer. Score: {score}, Analysis: {analysis}")
        # 4. Cáº­p nháº­t láº¡i attempt cuá»‘i cÃ¹ng
        last_attempt.answer = answer
        last_attempt.score = score
        last_attempt.analysis = analysis

        # 5. Update state (Ä‘iá»ƒm, sá»‘ láº§n, Ä‘á»™ khÃ³â€¦)
        self.update_state_after_question(state, last_question, answer, score, analysis)

        # 6. Náº¿u káº¿t thÃºc
        if state.is_finished:
            summary = self.generate_summary(state)
            return {"finished": True, "summary": summary}

        # 7. Náº¿u chÆ°a káº¿t thÃºc â†’ sinh cÃ¢u há»i má»›i & append vÃ o history
        next_question = self.generate_question(
            state.topic,
            state.current_difficulty,
            f"ÄÃ£ há»i {state.total_questions_asked} cÃ¢u"
        )

        state.history.append(QuestionAttempt(
            question=next_question,
            answer="",
            score=0.0,
            analysis="(pending answer)",
            difficulty=state.current_difficulty,
            timestamp=datetime.datetime.now().isoformat()
        ))

        return {
            "finished": False,
            "score": score,
            "analysis": analysis,
            "next_question": next_question,
            "difficulty": state.current_difficulty.value,
        }

    def generate_summary(self, state: InterviewState) -> Dict:
        """Generate final interview summary"""
        print("\n" + "=" * 50)
        print("ğŸ“ Tá»”NG Káº¾T PHá»NG Váº¤N")
        print("=" * 50)

        summary = {
            "candidate_info": {
                "name": state.candidate_name,
                "profile": state.profile,
                "classified_level": state.level.value
            },
            "interview_stats": {
                "timestamp": datetime.datetime.now().isoformat(),
                "total_questions": len(state.history),
                "final_score": state.final_score,
                "topic": state.topic
            },
            "question_history": []
        }

        for i, attempt in enumerate(state.history, 1):
            q_info = {

                "question_number": i,
                "difficulty": attempt.difficulty.value,
                "question": attempt.question,
                "answer": attempt.answer,
                "score": attempt.score,
                "analysis": attempt.analysis
            }
            summary["question_history"].append(q_info)

            print(f"\nCÃ¢u {i} ({attempt.difficulty.value}):")
            print(f"Q: {attempt.question}")
            print(f"A: {attempt.answer}")
            print(f"Score: {attempt.score}/10 - {attempt.analysis}")

        print(f"\nğŸ† ÄIá»‚M Tá»”NG Káº¾T: {state.final_score:.1f}/10")

        return summary


# # =======================
# # 5. Usage Example
# # =======================
#
# if __name__ == "__main__":
#     from pymongo import MongoClient
#
#     # Káº¿t ná»‘i MongoDB
#     client = MongoClient("mongodb://localhost:27017/")
#     db = client["interviewer_ai"]
#     collection = db["interview_results"]
#     interviewer = AdaptiveInterviewer()
#
#     # Test cases
#     test_cases = [
#         ("NgÃ´ VÄƒn PhÃ¡t,KT1", "Kiá»ƒu dá»¯ liá»‡u trong Java"),
#
#     ]
#
